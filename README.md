# Projet Donn√©es Distribu√©es ‚Äî Pipeline Big Data

## üß† Objectif du projet

Ce projet a pour but de **mettre en place un pipeline de traitement distribu√© de donn√©es a√©ronautiques** en temps r√©el, en s'appuyant sur un √©cosyst√®me Big Data complet :  
**NiFi ‚Üí Kafka ‚Üí Spark ‚Üí PostgreSQL ‚Üí Grafana**.

L‚Äôobjectif est de :
- Collecter des donn√©es d‚Äôa√©roports ou de vols via une API open source (comme AviationStack ou OpenAIP).
- Ingest ces donn√©es dans Kafka √† l‚Äôaide d‚Äôun flux NiFi.
- Traiter et nettoyer les flux en temps r√©el avec **Apache Spark Structured Streaming**.
- Stocker les r√©sultats dans une base de donn√©es **PostgreSQL** accessible via **pgAdmin**.
- Restituer les donn√©es r√©colt√©es via **Grafana**.

---

## ‚öôÔ∏è Architecture technique

<p align="center">
  <img src="Image/StructureProjet.png" width="400">
</p>


## üß© Technologies utilis√©es

|Logo| Composant | Technologie | R√¥le |
|----|-----------|-------------|------|
|<img src="Image/NIFI.png" width="80">| **NiFi** | apache nifi:1.28.0 | Collecte et routage des donn√©es depuis l‚ÄôAPI |
|<img src="Image/KAFKA.png" width="80">| **Kafka** | Apache Kafka 3.5 | File de messages pour la diffusion temps r√©el |
|<img src="Image/SPARK.png" width="80">| **Spark** | apache spark:3.5.0 | Traitement et transformation des donn√©es |
|<img src="Image/PgAdmin.png" width="80">| **PostgreSQL** | PostgreSQL 15 | Stockage persistant et structur√© |
|<img src="Image/PgAdmin.png" width="80">| **pgAdmin** | Interface web | Consultation et gestion de la base de donn√©es |
|<img src="Image/DOCKER.png" width="80">| **Docker Compose** | Orchestration | D√©marrage automatis√© de tous les services |
|<img src="Image/Grafana.png" width="80">| **Grafana** | grafana-enterprise:latest | Restitution graphique |

---

## üê≥ D√©marrage du projet

### Docker Compose :

Aper√ßu du fichier `docker-compose.py` :

```python
# docker-compose.py - aper√ßu
version = "3.9"

services = {
    "nifi": {
        "image": "apache/nifi:1.28.0",
        "ports": ["8443:8443"],
        ...
    },
    "kafka": {
        "image": "confluentinc/cp-kafka:7.5.0",
        ...
    },
    # (code tronqu√©)
}

```
[Voir le fichier complet](docker-compose.py)


### 2Ô∏è‚É£ Acc√®s aux interfaces :

| Service      | URL                        |
|-------------|----------------------------|
| NIFI        | [https://localhost:8443/nifi](https://localhost:8443/nifi) |
| PgAdmin     | [http://localhost:5050](http://localhost:5050) |
| Spark Master| [http://localhost:8080](http://localhost:8080) |
| Grafana     | [http://localhost:3000](http://localhost:3000) |

### <img src="Image/NIFI.png" width="30"> 1Ô∏è‚É£ R√©cup√©ration des donn√©es avec Apache NiFi :
- **R√¥le :** Collecte et routage des donn√©es depuis les API a√©ronautiques.  
- Connecteurs vers diff√©rentes APIs.  
- Pr√©traitement l√©ger (filtrage, enrichissement).  
- Envoi vers Kafka pour diffusion en temps r√©el.  

![](Image/StructureNIFI.png)

- InvokeHTTP : **Connexion √† l‚ÄôAPI** externe pour r√©cup√©rer les donn√©es a√©ronautiques.
- EvaluateJsonPath : **Analyse le JSON** re√ßu pour extraire les champs sp√©cifiques
- AttributesToJSON : **Convertit les attributs** NiFi extraits en nouveau flux JSON structur√©
- PublishKafkaRecord : Envoie les donn√©es transform√©es **vers un topic Kafka**
- LogAttribute : **Composant de debug** et de suivi

### <img src="Image/KAFKA.png" width="30"> 2Ô∏è‚É£ Apache Kafka
- **R√¥le :** File de messages pour diffuser les donn√©es en temps r√©el.  
- Producteurs : NiFi envoie les donn√©es.  
- Topics : organisent les flux par type de donn√©es.  
- Consommateurs : Spark r√©cup√®re les donn√©es pour traitement. 

### <img src="Image/SPARK.png" width="30"> 3Ô∏è‚É£ Apache Spark (Structured Streaming)
- **R√¥le :** Traitement et nettoyage des flux en temps r√©el.  
- Calculs sur flux en continu.  
- Nettoyage, transformation et agr√©gation des donn√©es. 

Afin de r√©aliser les traitements, un fichier PySpark a √©t√© cr√©e : **Streaming-processor**
Ce script g√®re le traitement en temps r√©el des donn√©es d‚Äôa√©roports provenant de Kafka, avant de les ins√©rer dans PostgreSQL.

**Voici les grandes √©tapes du pipeline Spark :**

| üß© √âtape | ‚öôÔ∏è Fonction | üß† Description |
|:--:|:--|:--|
| 1Ô∏è‚É£ | **Configuration** | Charge les d√©pendances **Kafka** et **PostgreSQL** |
| 2Ô∏è‚É£ | **Sch√©mas** | D√©crit la structure des **donn√©es d‚Äôa√©roports** |
| 3Ô∏è‚É£ | **SparkSession** | Initialise **Spark** avec les bons connecteurs |
| 4Ô∏è‚É£ | **Lecture** | R√©cup√®re les **donn√©es JSON** depuis **Kafka** |
| 5Ô∏è‚É£ | **Transformation** | Nettoie et **normalise les champs importants** |
| 6Ô∏è‚É£ | **Debug** | Affiche les **donn√©es dans la console** |
| 7Ô∏è‚É£ | **√âcriture** | Ins√®re les **a√©roports dans PostgreSQL** |
| 8Ô∏è‚É£ | **Ex√©cution** | Laisse le **streaming tourner en continu** |

Aper√ßu du fichier `Streaming-processor.py` :

```python
# Streaming-processor.py - aper√ßu
from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, explode
from pyspark.sql.types import StructType, StructField, StringType

spark = SparkSession.builder.appName("AirportDataProcessing").getOrCreate()

# Lecture du flux Kafka
kafka_df = spark.readStream.format("kafka")\
    .option("kafka.bootstrap.servers", "kafka:9093")\
    .option("subscribe", "airports")\
    .load()

# (code tronqu√©)
```
[Voir le fichier complet](Streaming-processor.py)

### <img src="Image/PgAdmin.png" width="30"> 4Ô∏è‚É£ PostgreSQL + pgAdmin
- **R√¥le :** Stockage persistant et gestion de la base de donn√©es.  
- pgAdmin pour explorer les tables et ex√©cuter des requ√™tes.

Il y a dans l'API une vingtaine de colonnes. Toutes ont √©t√© r√©colt√©es et stock√©es dans PostgreSQL

<p align="center">
  <img src="Image/ColonnePgAdmin.png" width="400">
</p>

**Voici ci-dessous un √©chantillon de nos donn√©es**
[](image/TableauPgAdmin.png)


### <img src="Image/Grafana.png" width="30"> 5Ô∏è‚É£ Grafana
- **R√¥le :** Visualisation graphique des donn√©es en temps r√©el.  
- **Fonctionnalit√©s principales :**  
  - Cr√©ation de **dashboards** pour repr√©senter les donn√©es d‚Äôa√©roports.  
  - Graphiques, alertes et indicateurs cl√©s (**KPI**).

**Voici par exemple deux graphiques :**

<p align="center">
  <img src="Image/CodeGraph.png" width="400" style="margin-right: 20px;">
  <img src="Image/Graph.png" width="250">
</p>

<p align="center">
  <img src="Image/Carte.png" width="600">
</p>


## üèÅ Conclusion

Ce projet, r√©alis√© dans le cadre du cours **Donn√©es Distribu√©es**, illustre la mise en place d‚Äôun **pipeline de donn√©es distribu√©es** complet pour le traitement en temps r√©el de donn√©es a√©ronautiques.  

Gr√¢ce √† l‚Äôint√©gration de **NiFi, Kafka, Spark, PostgreSQL et Grafana**, nous avons pu :  

- Collecter et centraliser des donn√©es depuis une API a√©ronautique.  
- Traiter et nettoyer ces flux en temps r√©el avec Spark Structured Streaming.  
- Stocker les r√©sultats de mani√®re structur√©e et persistante dans PostgreSQL.  
- Visualiser les informations et indicateurs cl√©s via des dashboards Grafana.  

Le projet d√©montre √©galement l‚Äôimportance de **Docker Compose** pour orchestrer facilement l‚Äôensemble des services et faciliter le d√©ploiement.  