# Projet Donn√©es Distribu√©es ‚Äî Pipeline Big Data

## üß† Objectif du projet

Ce projet a pour but de **mettre en place un pipeline de traitement distribu√© de donn√©es a√©ronautiques** en temps r√©el, en s'appuyant sur un √©cosyst√®me Big Data complet :  
**NiFi ‚Üí Kafka ‚Üí Spark ‚Üí PostgreSQL ‚Üí Grafana**.

L‚Äôobjectif est de :
- Collecter des donn√©es d‚Äôa√©roports ou de vols via une API open source (comme AviationStack ou OpenAIP).
- Ingest ces donn√©es dans Kafka √† l‚Äôaide d‚Äôun flux NiFi.
- Traiter et nettoyer les flux en temps r√©el avec **Apache Spark Structured Streaming**.
- Stocker les r√©sultats dans une base de donn√©es **PostgreSQL** accessible via **pgAdmin**.
- Restituer les donn√©es r√©colt√©es via **Grafana**.

---

## ‚öôÔ∏è Architecture technique

(Image/StructureProjet.png)


## üß© Technologies utilis√©es

|Logo| Composant | Technologie | R√¥le |
|----|-----------|-------------|------|
|(Image/NIFI.png)| **NiFi** | apache nifi:1.28.0 | Collecte et routage des donn√©es depuis l‚ÄôAPI |
|(Image/KAFKA.png)| **Kafka** | Apache Kafka 3.5 | File de messages pour la diffusion temps r√©el |
|(Image/SPARK.png)| **Spark** | apache spark:3.5.0 | Traitement et transformation des donn√©es |
|(Image/PgAdmin.png)| **PostgreSQL** | PostgreSQL 15 | Stockage persistant et structur√© |
|(Image/PgAdmin.png)| **pgAdmin** | Interface web | Consultation et gestion de la base de donn√©es |
|(Image/DOCKER.png)| **Docker Compose** | Orchestration | D√©marrage automatis√© de tous les services |
|(Image/GRAFANA.png)| **Grafana** | grafana-enterprise:latest | Restitution graphique |

---

## üê≥ D√©marrage du projet

### Docker Compose :

(docker-compose.py)

### 2Ô∏è‚É£ Acc√®s aux interfaces :

| Service      | URL                        |
|-------------|----------------------------|
| NIFI        | [https://localhost:8443/nifi](https://localhost:8443/nifi) |
| PgAdmin     | [http://localhost:5050](http://localhost:5050) |
| Spark Master| [http://localhost:8080](http://localhost:8080) |
| Grafana     | [http://localhost:3000](http://localhost:3000) |

### (Image/NIFI.png) | 1Ô∏è‚É£ R√©cup√©ration des donn√©es avec Apache NiFi :
- **R√¥le :** Collecte et routage des donn√©es depuis les API a√©ronautiques.  
- Connecteurs vers diff√©rentes APIs.  
- Pr√©traitement l√©ger (filtrage, enrichissement).  
- Envoi vers Kafka pour diffusion en temps r√©el.  

(Image/StructureNIFI.png)

- InvokeHTTP : **Connexion √† l‚ÄôAPI** externe pour r√©cup√©rer les donn√©es a√©ronautiques.
- EvaluateJsonPath : **Analyse le JSON** re√ßu pour extraire les champs sp√©cifiques
- AttributesToJSON : **Convertit les attributs** NiFi extraits en nouveau flux JSON structur√©
- PublishKafkaRecord : Envoie les donn√©es transform√©es **vers un topic Kafka**
- LogAttribute : **Composant de debug** et de suivi

### (Image/KAFKA.png) | 2Ô∏è‚É£ Apache Kafka
- **R√¥le :** File de messages pour diffuser les donn√©es en temps r√©el.  
- Producteurs : NiFi envoie les donn√©es.  
- Topics : organisent les flux par type de donn√©es.  
- Consommateurs : Spark r√©cup√®re les donn√©es pour traitement. 

### (Image/SPARK.png) | 3Ô∏è‚É£ Apache Spark (Structured Streaming)
- **R√¥le :** Traitement et nettoyage des flux en temps r√©el.  
- Calculs sur flux en continu.  
- Nettoyage, transformation et agr√©gation des donn√©es. 

Afin de r√©aliser les traitements, un fichier PySpark a √©t√© cr√©e : **Streaming-processor**
Ce script g√®re le traitement en temps r√©el des donn√©es d‚Äôa√©roports provenant de Kafka, avant de les ins√©rer dans PostgreSQL.

Voici les grandes √©tapes du pipeline Spark :

| üß© √âtape | ‚öôÔ∏è Fonction | üß† Description |
|:--:|:--|:--|
| 1Ô∏è‚É£ | **Configuration** | Charge les d√©pendances **Kafka** et **PostgreSQL** |
| 2Ô∏è‚É£ | **Sch√©mas** | D√©crit la structure des **donn√©es d‚Äôa√©roports** |
| 3Ô∏è‚É£ | **SparkSession** | Initialise **Spark** avec les bons connecteurs |
| 4Ô∏è‚É£ | **Lecture** | R√©cup√®re les **donn√©es JSON** depuis **Kafka** |
| 5Ô∏è‚É£ | **Transformation** | Nettoie et **normalise les champs importants** |
| 6Ô∏è‚É£ | **Debug** | Affiche les **donn√©es dans la console** |
| 7Ô∏è‚É£ | **√âcriture** | Ins√®re les **a√©roports dans PostgreSQL** |
| 8Ô∏è‚É£ | **Ex√©cution** | Laisse le **streaming tourner en continu** |

(Streaming-processor.py)


### 4Ô∏è‚É£ PostgreSQL + pgAdmin
- **R√¥le :** Stockage persistant et gestion de la base de donn√©es.  
- pgAdmin pour explorer les tables et ex√©cuter des requ√™tes.

### 5Ô∏è‚É£ Grafana
- **R√¥le :** Visualisation graphique des donn√©es en temps r√©el.  
- **Fonctionnalit√©s principales :**  
  - Cr√©ation de **dashboards** pour repr√©senter les donn√©es d‚Äôa√©roports.  
  - Graphiques, alertes et indicateurs cl√©s (**KPI**).